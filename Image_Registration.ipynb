{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqQ9XKPMYfuo",
        "outputId": "8ec5d7d2-2548-47ef-e2b3-34158a34a475"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "19f1n2AB1mpZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Open the image files.\n",
        "img1_color = cv2.imread(\"/content/drive/MyDrive/Img_regis/Example2_moving.tif\") # Image to be aligned.\n",
        "img2_color = cv2.imread(\"/content/drive/MyDrive/Img_regis/Example2_fixed.tif\") # Reference image.\n",
        "\n",
        "# Convert to grayscale.\n",
        "img1 = cv2.cvtColor(img1_color, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(img2_color, cv2.COLOR_BGR2GRAY)\n",
        "height, width = img2.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ORB detector with 5000 features.\n",
        "orb_detector = cv2.ORB_create(5000)"
      ],
      "metadata": {
        "id": "GNFIlLLC4AjJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find keypoints and descriptors.\n",
        "# The first arg is the image, second arg is the mask\n",
        "# (which is not required in this case).\n",
        "kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
        "kp2, d2 = orb_detector.detectAndCompute(img2, None)"
      ],
      "metadata": {
        "id": "-dnzY74W4ExI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Match features between the two images.\n",
        "# We create a Brute Force matcher with\n",
        "# Hamming distance as measurement mode.\n",
        "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck = True)"
      ],
      "metadata": {
        "id": "r-nSAJhE4HZz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Match the two sets of descriptors.\n",
        "matches = matcher.match(d1, d2)\n",
        "matches = list(matches)"
      ],
      "metadata": {
        "id": "Fwlg7oDe4HjE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort matches on the basis of their Hamming distance.\n",
        "matches.sort(key = lambda x: x.distance)"
      ],
      "metadata": {
        "id": "51bB3ypf4Ou3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the top 90 % matches forward.\n",
        "matches = matches[:int(len(matches)*0.75)]\n",
        "no_of_matches = len(matches)"
      ],
      "metadata": {
        "id": "lkzWJOFL4ROr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define empty matrices of shape no_of_matches * 2.\n",
        "p1 = np.zeros((no_of_matches, 2))\n",
        "p2 = np.zeros((no_of_matches, 2))"
      ],
      "metadata": {
        "id": "unRjc_XH4UDz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(matches)):\n",
        "  p1[i, :] = kp1[matches[i].queryIdx].pt\n",
        "  p2[i, :] = kp2[matches[i].trainIdx].pt"
      ],
      "metadata": {
        "id": "VTebQyc54Xm4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the homography matrix.\n",
        "homography, mask = cv2.findHomography(p1, p2, cv2.RANSAC)"
      ],
      "metadata": {
        "id": "ml-zWBDi4n6w"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this matrix to transform the\n",
        "# colored image wrt the reference image.\n",
        "transformed_img = cv2.warpPerspective(img1_color,\n",
        "\t\t\t\t\thomography, (width, height))\n",
        "\n",
        "# Save the output.\n",
        "cv2.imwrite('output.tif', transformed_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuSuFf533_C5",
        "outputId": "9f600d2d-b532-48b0-a8a0-85071ec1c172"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "# Compute reprojection error\n",
        "points1_reproj = cv2.perspectiveTransform(p1.reshape(-1, 1, 2), homography).reshape(-1, 2)\n",
        "reproj_error = np.mean(np.sqrt(np.sum((p2 - points1_reproj)**2, axis=1)))"
      ],
      "metadata": {
        "id": "eFBRpOobmtbt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reprojection Error:\", reproj_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXedlcTcmvYG",
        "outputId": "abe6ff47-b075-4871-c466-60bba6e2ede0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reprojection Error: 3371.088583054692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute feature matching accuracy\n",
        "matching_accuracy = len(matches) / len(d1)\n",
        "print(\"Matching Accuracy:\", matching_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvRqhtu6m0ye",
        "outputId": "e91b4e91-e43b-4aea-b1eb-923b8a8164d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Accuracy: 0.0812699680511182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZEhQ7gYGUfA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}